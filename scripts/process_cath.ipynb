{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Links\n",
    "Splits: https://dl.fbaipublicfiles.com/fair-esm/data/cath4.3_topologysplit_202206/splits.json\n",
    "Coords & Sequences: https://dl.fbaipublicfiles.com/fair-esm/data/cath4.3_topologysplit_202206/chain_set.jsonl\n",
    "\n",
    "Taken from: https://github.com/facebookresearch/esm/tree/main/examples/inverse_folding#data-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the path below with the path to your local copy of the CATH dataset\n",
    "with open('data/cath/esm_if/chain_set.jsonl', 'r') as json_file:\n",
    "    all_prots = [json.loads(json_str) for json_str in list(json_file)]\n",
    "    \n",
    "with open(\"data/cath/esm_if/splits.json\", \"r\") as f:\n",
    "    splits = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_coords(coord_dict):\n",
    "    N_coords = coord_dict[\"N\"]\n",
    "    CA_coords = coord_dict[\"CA\"]\n",
    "    C_coords = coord_dict[\"C\"]\n",
    "    coords = np.stack([N_coords, CA_coords, C_coords], axis=1)\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "test = []\n",
    "val = []\n",
    "unk_ids = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 200 proteins...\n",
      "Processed 400 proteins...\n",
      "Processed 600 proteins...\n",
      "Processed 800 proteins...\n",
      "Processed 1000 proteins...\n",
      "Processed 1200 proteins...\n",
      "Processed 1400 proteins...\n",
      "Processed 1600 proteins...\n",
      "Processed 1800 proteins...\n",
      "Processed 2000 proteins...\n",
      "Processed 2200 proteins...\n",
      "Processed 2400 proteins...\n",
      "Processed 2600 proteins...\n",
      "Processed 2800 proteins...\n",
      "Processed 3000 proteins...\n",
      "Processed 3200 proteins...\n",
      "Processed 3400 proteins...\n",
      "Processed 3600 proteins...\n",
      "Processed 3800 proteins...\n",
      "Processed 4000 proteins...\n",
      "Processed 4200 proteins...\n",
      "Processed 4400 proteins...\n",
      "Processed 4600 proteins...\n",
      "Processed 4800 proteins...\n",
      "Processed 5000 proteins...\n",
      "Processed 5200 proteins...\n",
      "Processed 5400 proteins...\n",
      "Processed 5600 proteins...\n",
      "Processed 5800 proteins...\n",
      "Processed 6000 proteins...\n",
      "Processed 6200 proteins...\n",
      "Processed 6400 proteins...\n",
      "Processed 6600 proteins...\n",
      "Processed 6800 proteins...\n",
      "Processed 7000 proteins...\n",
      "Processed 7200 proteins...\n",
      "Processed 7400 proteins...\n",
      "Processed 7600 proteins...\n",
      "Processed 7800 proteins...\n",
      "Processed 8000 proteins...\n",
      "Processed 8200 proteins...\n",
      "Processed 8400 proteins...\n",
      "Processed 8600 proteins...\n",
      "Processed 8800 proteins...\n",
      "Processed 9000 proteins...\n",
      "Processed 9200 proteins...\n",
      "Processed 9400 proteins...\n",
      "Processed 9600 proteins...\n",
      "Processed 9800 proteins...\n",
      "Processed 10000 proteins...\n",
      "Processed 10200 proteins...\n",
      "Processed 10400 proteins...\n",
      "Processed 10600 proteins...\n",
      "Processed 10800 proteins...\n",
      "Processed 11000 proteins...\n",
      "Processed 11200 proteins...\n",
      "Processed 11400 proteins...\n",
      "Processed 11600 proteins...\n",
      "Processed 11800 proteins...\n",
      "Processed 12000 proteins...\n",
      "Processed 12200 proteins...\n",
      "Processed 12400 proteins...\n",
      "Processed 12600 proteins...\n",
      "Processed 12800 proteins...\n",
      "Processed 13000 proteins...\n",
      "Processed 13200 proteins...\n",
      "Processed 13400 proteins...\n",
      "Processed 13600 proteins...\n",
      "Processed 13800 proteins...\n",
      "Processed 14000 proteins...\n",
      "Processed 14200 proteins...\n",
      "Processed 14400 proteins...\n",
      "Processed 14600 proteins...\n",
      "Processed 14800 proteins...\n",
      "Processed 15000 proteins...\n",
      "Processed 15200 proteins...\n",
      "Processed 15400 proteins...\n",
      "Processed 15600 proteins...\n",
      "Processed 15800 proteins...\n",
      "Processed 16000 proteins...\n",
      "Processed 16200 proteins...\n",
      "Processed 16400 proteins...\n",
      "Processed 16600 proteins...\n",
      "Processed 16800 proteins...\n",
      "Processed 17000 proteins...\n",
      "Processed 17200 proteins...\n",
      "Processed 17400 proteins...\n",
      "Processed 17600 proteins...\n",
      "Processed 17800 proteins...\n",
      "Processed 18000 proteins...\n",
      "Processed 18200 proteins...\n",
      "Processed 18400 proteins...\n",
      "Processed 18600 proteins...\n",
      "Processed 18800 proteins...\n",
      "Processed 19000 proteins...\n",
      "Processed 19200 proteins...\n",
      "Processed 19400 proteins...\n",
      "Processed 19600 proteins...\n",
      "Processed 19800 proteins...\n",
      "Processed 20000 proteins...\n",
      "Processed 20200 proteins...\n",
      "Processed 20400 proteins...\n",
      "Processed 20600 proteins...\n",
      "Processed 20800 proteins...\n",
      "Processed 21000 proteins...\n",
      "Processed 21200 proteins...\n",
      "Processed 21400 proteins...\n",
      "Processed 21600 proteins...\n",
      "Processed 21800 proteins...\n",
      "Processed 22000 proteins...\n",
      "Processed 22200 proteins...\n",
      "Processed 22400 proteins...\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for item in all_prots:\n",
    "    i += 1\n",
    "    processed = {\n",
    "        \"id\": item[\"name\"],\n",
    "        \"seq\": item[\"seq\"],\n",
    "        \"coords\": format_coords(item[\"coords\"]),\n",
    "    }\n",
    "\n",
    "    if item[\"name\"] in splits[\"train\"]:\n",
    "        train.append(processed)\n",
    "    elif item[\"name\"] in splits[\"validation\"]:\n",
    "        val.append(processed)\n",
    "    elif item[\"name\"] in splits[\"test\"]:\n",
    "        test.append(processed)\n",
    "    else:\n",
    "        # print(f\"Unknown protein split: {item['name']}\")\n",
    "        unk_ids.append(processed[\"id\"])\n",
    "    \n",
    "    if i % 200 == 0:\n",
    "        print(f\"Processed {i} proteins...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16699, 1529, 1882, 2398)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(val), len(test), len(unk_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save everything\n",
    "import pickle\n",
    "\n",
    "with open(\"data/cath/train.pkl\", \"wb\") as f:\n",
    "    pickle.dump(train, f)\n",
    "with open(\"data/cath/val.pkl\", \"wb\") as f:\n",
    "    pickle.dump(val, f)\n",
    "with open(\"data/cath/test.pkl\", \"wb\") as f:\n",
    "    pickle.dump(test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inverse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
